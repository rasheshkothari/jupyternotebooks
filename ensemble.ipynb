{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lightweight-protein",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rkothari/.local/lib/python3.7/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "import jellyfish\n",
    "import snowflake.connector\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-scout",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/Downloads/invoice_product_descriprions',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-annex",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = data[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-cornwall",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cnx = snowflake.connector.connect(user='rkothari', password='Fall19@123', account='FF80747.east-us-2.azure', warehouse='DASCI_WH_XS', database='FDC_STAGE', schema='DASCI', role='DASCI_DEVELOPER')\n",
    "\n",
    "# con = cnx.cursor()\n",
    "\n",
    "# query = \"\"\"SELECT DISTINCT pm.GTIN, i.INVOICE_PACKAGE_DESCRIPTION, pm.PRODUCT_DESCRIPTION, pm.INVOICE_UPC_CASE\n",
    "#         FROM FDC_PROD_LIVE.FDC02.ENTITY_INVOICE i\n",
    "#         JOIN PRODUCT_MASTER_CATALOG_MAPPED_TEMP pm on pm.INVOICE_ITEM_FTS_ID = i.INVOICE_ITEM_FTS_ID\n",
    "#         WHERE INVOICE_PACKAGE_DESCRIPTION not in (SELECT INVOICE_PACKAGE_DESCRIPTION FROM INVOICE_NONPRODUCT_FILTER)\n",
    "#             and i.INVOICE_DATE >= '2020-01-01'\n",
    "#         GROUP BY pm.GTIN, i.INVOICE_PACKAGE_DESCRIPTION, pm.PRODUCT_DESCRIPTION, pm.INVOICE_UPC_CASE\n",
    "#         ORDER BY pm.GTIN\"\"\"\n",
    "# results = con.execute(query)\n",
    "# res = pd.DataFrame.from_records(iter(results), columns=[y[0] for y in results.description])\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "# con.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-census",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-microwave",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = time.time()\n",
    "res['fuzz_partial_ratio'] = res.apply(lambda x: fuzz.partial_ratio(x.INVOICE_PACKAGE_DESCRIPTION, x.PRODUCT_DESCRIPTION), axis=1)\n",
    "end = time.time()\n",
    "print('Time taken by fuzz_partial_ratio ', (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-millennium",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-adaptation",
   "metadata": {},
   "outputs": [],
   "source": [
    "res['INVOICE_SOUNDEX'] = res.apply(lambda x: jellyfish.soundex(x.INVOICE_PACKAGE_DESCRIPTION), axis=1) \n",
    "res['PRODUCT_DESCRIPTION_SOUNDEX'] = res.apply(lambda x: jellyfish.soundex(x.PRODUCT_DESCRIPTION), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "res['jellyfish_ratio'] = res.apply(lambda x: fuzz.partial_ratio(x.INVOICE_SOUNDEX, x.PRODUCT_DESCRIPTION_SOUNDEX), axis=1)\n",
    "end = time.time()\n",
    "print('Time taken by fuzz_partial_ratio ', (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported the inaugural corpus from nltk.corpus\n",
    "import nltk\n",
    "from nltk.corpus import inaugural\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "res['INVOICE_tokens'] = res.apply(lambda x: nltk.word_tokenize(x.INVOICE_PACKAGE_DESCRIPTION), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-qatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "res['product_tokens'] = res.apply(lambda x: nltk.word_tokenize(x.PRODUCT_DESCRIPTION), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(nltk.ngrams(tokens1, n=3))\n",
    "\n",
    "res['INVOICE_ngram'] = res['INVOICE_tokens'].apply(lambda r: list(nltk.ngrams(r,n=2)))\n",
    "res['product_ngrams'] = res['product_tokens'].apply(lambda r: list(nltk.ngrams(r,n=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "res['INVOICE_ngram'] = res['INVOICE_tokens'].apply(lambda r: set(nltk.ngrams(r,n=2)))\n",
    "res['product_ngrams'] = res['product_tokens'].apply(lambda r: set(nltk.ngrams(r,n=2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-russian",
   "metadata": {},
   "outputs": [],
   "source": [
    "res['fuzz_ratio_ngrams'] = res.apply(lambda x: fuzz.partial_ratio(x.INVOICE_ngram, x.product_ngrams), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.jaccard_distance(ng1_tokens, ng3_tokens)\n",
    "# res['jellyfish_ratio'] = res.apply(lambda x: fuzz.partial_ratio(x.INVOICE_SOUNDEX, x.PRODUCT_DESCRIPTION_SOUNDEX), axis=1)\n",
    "\n",
    "res['jaccard_distance'] = res.apply(lambda x: 1-nltk.jaccard_distance(set(x.INVOICE_tokens) , set(x.product_tokens)),axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-worcester",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res['string_invoice_ngram'] = [','.join(map(str, l)) for l in res['INVOICE_tokens']]\n",
    "res['string_product_ngram'] = [','.join(map(str, l)) for l in res['product_tokens']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-seller",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "otherwise-roads",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(word1, word2,soundex1, soundex2, ngram1, ngram2):\n",
    "    \n",
    "    score_1 = fuzz.partial_ratio(word1, word2) # score from fuzzywuzzy\n",
    "    score_2 = fuzz.partial_ratio(soundex1,soundex2) #jellyfish score\n",
    "    score_3 = fuzz.partial_ratio(ngram1, ngram2)  #fuzzy_wuzzy on ngram\n",
    "    \n",
    "        \n",
    "    score = 0.14*score_1+ 0.64*score_2 +0.18*score_3# customize your own weights \n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-hygiene",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "res['weight_match'] = res.apply(lambda x: similarity(x.INVOICE_PACKAGE_DESCRIPTION, x.PRODUCT_DESCRIPTION, \n",
    "                                                     x.INVOICE_SOUNDEX ,x.PRODUCT_DESCRIPTION_SOUNDEX, \n",
    "                                                     x.string_invoice_ngram, x.string_product_ngram), axis = 1)\n",
    "end = time.time()\n",
    "print('Time taken by fuzz_partial_ratio ', (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extra-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_wieghts = res[[\"INVOICE_PACKAGE_DESCRIPTION\",\"PRODUCT_DESCRIPTION\",\"fuzz_partial_ratio\",\"jellyfish_ratio\",\"fuzz_ratio_ngrams\", \"weight_match\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_wieghts.sort_values(by=['weight_match'],ascending=False,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_wieghts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = res[[\"fuzz_partial_ratio\",\"jellyfish_ratio\",\"fuzz_ratio_ngrams\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-penalty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-booking",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-messaging",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specific-tract",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-writing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-aspect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-portrait",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-scholarship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# res.columns\n",
    "master_wieghts.to_csv(\"~/Downloads/master_wieghts.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-rental",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-triple",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total time taken:\" , (main_end - main_start ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-basket",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.dot([2.5,-5.0,-1.2,0.5,2.0,0.7] ,[3,2,1,3,0,4.19])+0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[res['INVOICE_PACKAGE_DESCRIPTION'] == 'OB DRY CIDER 4/6 CAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-component",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[res['INVOICE_PACKAGE_DESCRIPTION'] == 'OB DRY CIDER 4/6 CAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = set('Data is the new oil of the digital economy')\n",
    "w2 = set('Data is a new oil')\n",
    " \n",
    "print(nltk.jaccard_distance(w1, w2))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classical-florida",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard_Similarity(doc1, doc2): \n",
    "    \n",
    "    # List the unique words in a document\n",
    "#     words_doc1 = set(doc1.lower().split()) \n",
    "#     words_doc2 = set(doc2.lower().split())\n",
    "    \n",
    "    # Find the intersection of words list of doc1 & doc2\n",
    "    intersection = doc1.intersection(doc2)\n",
    "    print(intersection)\n",
    "    # Find the union of words list of doc1 & doc2\n",
    "    union = doc1.union(doc2)\n",
    "    print(union)\n",
    "    # Calculate Jaccard similarity score \n",
    "    # using length of intersection set divided by length of union set\n",
    "    return float(len(intersection)) / len(union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "detected-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "jellyfish_main_str = jellyfish.soundex('11221250')\n",
    "jellyfish_comp_str = jellyfish.soundex('1112321240')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "united-respect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1000'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jellyfish_main_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dying-heading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1000'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jellyfish_comp_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "patent-handle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100--->67\n"
     ]
    }
   ],
   "source": [
    "print(fuzz.partial_ratio(jellyfish_main_str, jellyfish_comp_str), end='--->')\n",
    "print(fuzz.partial_ratio('1122121250','112287250'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = set(['BUD', '16OZ', '4/6', 'CAN'])\n",
    "w2 = set(['BUDWEISER', 'BEER', '12', 'CT', '12', 'OZ', 'CAN', 'IN', 'BOX', '144', 'OZ'])\n",
    "\n",
    "Jaccard_Similarity(w1,w2)\n",
    "print(1-nltk.cjaccard_distance(w1, w2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "heard-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.util import ngrams\n",
    " \n",
    "s = \"Natural-language processing (NLP) is an area of computer science \" \\\n",
    "    \"and artificial intelligence concerned with the interactions \" \\\n",
    "    \"between computers and human (natural) languages.\"\n",
    " \n",
    "s = s.lower()\n",
    "s = re.sub(r'[^a-zA-Z0-9\\s]', ' ', s)\n",
    "tokens = [token for token in s.split(\" \") if token != \"\"]\n",
    "output = list(ngrams(tokens, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "personalized-strain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('natural', 'language', 'processing', 'nlp', 'is'),\n",
       " ('language', 'processing', 'nlp', 'is', 'an'),\n",
       " ('processing', 'nlp', 'is', 'an', 'area'),\n",
       " ('nlp', 'is', 'an', 'area', 'of'),\n",
       " ('is', 'an', 'area', 'of', 'computer'),\n",
       " ('an', 'area', 'of', 'computer', 'science'),\n",
       " ('area', 'of', 'computer', 'science', 'and'),\n",
       " ('of', 'computer', 'science', 'and', 'artificial'),\n",
       " ('computer', 'science', 'and', 'artificial', 'intelligence'),\n",
       " ('science', 'and', 'artificial', 'intelligence', 'concerned'),\n",
       " ('and', 'artificial', 'intelligence', 'concerned', 'with'),\n",
       " ('artificial', 'intelligence', 'concerned', 'with', 'the'),\n",
       " ('intelligence', 'concerned', 'with', 'the', 'interactions'),\n",
       " ('concerned', 'with', 'the', 'interactions', 'between'),\n",
       " ('with', 'the', 'interactions', 'between', 'computers'),\n",
       " ('the', 'interactions', 'between', 'computers', 'and'),\n",
       " ('interactions', 'between', 'computers', 'and', 'human'),\n",
       " ('between', 'computers', 'and', 'human', 'natural'),\n",
       " ('computers', 'and', 'human', 'natural', 'languages')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query = \"\"\"SELECT DISTINCT pm.GTIN, i.INVOICE_PACKAGE_DESCRIPTION, pm.PRODUCT_DESCRIPTION, pm.GTIN\n",
    "#         FROM FDC_PROD_LIVE.FDC02.ENTITY_INVOICE i\n",
    "#         JOIN PRODUCT_MASTER_CATALOG_MAPPED_TEMP pm on pm.INVOICE_ITEM_FTS_ID = i.INVOICE_ITEM_FTS_ID\n",
    "#         WHERE INVOICE_PACKAGE_DESCRIPTION not in (SELECT INVOICE_PACKAGE_DESCRIPTION FROM INVOICE_NONPRODUCT_FILTER)\n",
    "#             and i.INVOICE_DATE >= '2020-01-01'\n",
    "#         GROUP BY pm.GTIN, i.INVOICE_PACKAGE_DESCRIPTION, pm.PRODUCT_DESCRIPTION\n",
    "#         ORDER BY pm.GTIN\"\"\"\n",
    " \n",
    "# mapped01 = pd.read_sql(query, cnx, coerce_float = False)\n",
    " \n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    " \n",
    "tokenizer = CountVectorizer(strip_accents='unicode',analyzer='char_wb',ngram_range=(3,3))\n",
    "featurenames = []\n",
    "sparse = []\n",
    "for i in central.itertuples():\n",
    "    x = tokenizer.fit_transform([i.PRODUCT_DESCRIPTION])\n",
    "    sparse.append(x.toarray())\n",
    "    featurenames.append(tokenizer.get_feature_names())\n",
    " \n",
    "card_docs = [TaggedDocument(row, [l]) for l, row in enumerate(featurenames)]\n",
    "model = Doc2Vec(vector_size=50, min_count=0, epochs=100, dm=1)\n",
    "model.build_vocab(card_docs)\n",
    "model.train(card_docs, total_examples=model.corpus_count, epochs=model.epochs)\n",
    " \n",
    "ranks = []\n",
    "for i in mapped01.itertuples():\n",
    "    inferred_vector = model.infer_vector(i.INVOICE_PACKAGE_DESCRIPTION.split(' '))\n",
    "    sims = model.wv.most_similar([inferred_vector], topn=len(card2vec))\n",
    "    print('Tested Line: ', i.INVOICE_PACKAGE_DESCRIPTION)\n",
    "    print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-simple",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
